{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemicai tutorial 5: ClassifierTree\n",
    "In this tutorial everything concerning the ClassifierTree will be explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemicai as gem\n",
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Initialising ClassifierTree\n",
    "First, we have to initialize the tree, to do this we need the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a default Classifier to initialize all nodes in the tree. \n",
    "# All specified attributres of the classifier will be the default for all nodes in the tree.\n",
    "module = models.resnet18(pretrained=False)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Classes can be set to [], as only the hyper parameters of the Classifier matter\n",
    "default_classifier = gem.Classifier(module, classes=[], loss_function=loss_function, enable_cuda=True)\n",
    "\n",
    "# Specify the labels the tree should classify. Make sure you specify them in the right order!\n",
    "relevant_labels = ['BodyPartExamined', 'StudyDescription']\n",
    "\n",
    "# Select base dataset for initialisation of classes\n",
    "gemset_path = '/mnt/SharedStor/gemset/DX/'\n",
    "base_dataset = gem.DicomoDataset.get_dicomo_dataset(gemset_path, relevant_labels)\n",
    "\n",
    "# Create a directory where you want to save the tree\n",
    "dx_tree_path = '/mnt/SharedStor/trees/dx_tree'\n",
    "\n",
    "# Calling this function will start initializing the tree\n",
    "# tree = gem.ClassifierTree(default_classifier, relevant_labels, base_dataset, dx_tree_path)\n",
    "# print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ClassifierTree consits of ClassifierNodes, when intialising the tree, its nodes are automatically saved. You can retrieve a tree by specifying its directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Depth | Label            |   Classifiers |   Avg. classes |\n",
      "|---------+------------------+---------------+----------------|\n",
      "|       0 | BodyPartExamined |             1 |           20   |\n",
      "|       1 | StudyDescription |            20 |            8.8 |\n"
     ]
    }
   ],
   "source": [
    "tree = None\n",
    "tree = gem.ClassifierTree.from_dir(dx_tree_path)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training the tree\n",
    "To train the whole tree at once, simply use the train function. But first we need a train and test dataset, to learn more about datasets check out tutorial 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class (BodyPartExamined)   |   Frequency |\n",
      "|----------------------------+-------------|\n",
      "| VERTEBRAL COLUMN           |         361 |\n",
      "| CHEST                      |        1970 |\n",
      "| KNEE                       |         959 |\n",
      "| EXTREMITY                  |         532 |\n",
      "| PELVIS                     |         354 |\n",
      "| TSPINE                     |          47 |\n",
      "| FOOT                       |         923 |\n",
      "| SHOULDER                   |         635 |\n",
      "| LSPINE                     |         287 |\n",
      "| ELBOW                      |         440 |\n",
      "| HIP                        |         381 |\n",
      "| CSPINE                     |         110 |\n",
      "| ANKLE                      |          96 |\n",
      "| HAND                       |         340 |\n",
      "| CLAVICLE                   |          28 |\n",
      "| ABDOMEN                    |          77 |\n",
      "| SKULL                      |          32 |\n",
      "| ARM                        |          22 |\n",
      "| LEG                        |          21 |\n",
      "| SSPINE                     |           1 |\n",
      "|                            |           1 |\n",
      "\n",
      "Total number of training images: 7617 \n",
      "Total number of classes: 21\n",
      "\n",
      "| Class (BodyPartExamined)   |   Frequency |\n",
      "|----------------------------+-------------|\n",
      "| VERTEBRAL COLUMN           |          89 |\n",
      "| CHEST                      |         479 |\n",
      "| KNEE                       |         247 |\n",
      "| EXTREMITY                  |         167 |\n",
      "| HIP                        |         101 |\n",
      "| TSPINE                     |          19 |\n",
      "| FOOT                       |         223 |\n",
      "| SHOULDER                   |         139 |\n",
      "| LSPINE                     |          51 |\n",
      "| ELBOW                      |         121 |\n",
      "| PELVIS                     |         102 |\n",
      "| CSPINE                     |          30 |\n",
      "| ANKLE                      |          26 |\n",
      "| HAND                       |          67 |\n",
      "| ARM                        |           2 |\n",
      "| ABDOMEN                    |          19 |\n",
      "| SKULL                      |           8 |\n",
      "| LEG                        |           9 |\n",
      "| CLAVICLE                   |           5 |\n",
      "\n",
      "Total number of training images: 1904 \n",
      "Total number of classes: 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_path = '/mnt/SharedStor/gemset/DX/train'\n",
    "test_path = '/mnt/SharedStor/gemset/DX/test'\n",
    "\n",
    "trainset = gem.DicomoDataset.get_dicomo_dataset(train_path, relevant_labels)\n",
    "testset = gem.DicomoDataset.get_dicomo_dataset(test_path, relevant_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of ClassifierTree /mnt/SharedStor/trees/dx_tree begun. Total nodes to train: 21\n",
      "|  Node | Depth | Parents              |  Classes | Train size |  Train acc | Elapsed  | \n",
      "|-------+-------+----------------------+----------+------------+------------+----------|\n",
      "|     1 |     0 | .                    |       20 |       6100 |      5.66% | 00:24:37 | \n",
      "|     2 |     1 | FOOT                 |       13 |        720 |     10.83% | 00:07:26 | \n",
      "|     3 |     1 | PELVIS               |       13 |        301 |      19.6% | 00:06:03 | \n",
      "|     4 |     1 | SKULL                |        2 |         30 |     83.33% | 00:05:03 | \n",
      "|     5 |     1 | SHOULDER             |       17 |        497 |       0.6% | 00:06:41 | \n",
      "|     6 |     1 | TSPINE               |        3 |         50 |       4.0% | 00:05:08 | \n",
      "|     7 |     1 | CSPINE               |        1 |         89 |     100.0% | 00:05:15 | \n",
      "|     8 |     1 | CLAVICLE             |        5 |         17 |      5.88% | 00:05:01 | \n",
      "|     9 |     1 | SSPINE               |        1 |          1 |     100.0% | 00:05:03 | \n",
      "|    10 |     1 | ARM                  |        3 |         16 |     18.75% | 00:04:59 | \n",
      "|    11 |     1 | ANKLE                |        9 |         78 |      6.41% | 00:05:13 | \n",
      "|    12 |     1 | KNEE                 |       15 |        736 |      0.82% | 00:07:25 | \n",
      "|    13 |     1 | LSPINE               |        5 |        224 |      1.79% | 00:05:43 | \n",
      "|    14 |     1 | LEG                  |        3 |         23 |      4.35% | 00:05:01 | \n",
      "|    15 |     1 | ABDOMEN              |        3 |         59 |     20.34% | 00:05:08 | \n",
      "|    16 |     1 | ELBOW                |       14 |        351 |      0.85% | 00:06:10 | \n",
      "|    17 |     1 | HAND                 |       17 |        252 |      1.59% | 00:05:48 | \n",
      "|    18 |     1 | HIP                  |       10 |        323 |      1.86% | 00:06:05 | \n",
      "|    19 |     1 | VERTEBRAL COLUMN     |        8 |        289 |     32.87% | 00:05:59 | \n",
      "|    20 |     1 | EXTREMITY            |       20 |        501 |      4.39% | 00:06:41 | \n",
      "|    21 |     1 | CHEST                |       14 |       1543 |      1.81% | 00:10:17 | \n"
     ]
    }
   ],
   "source": [
    "tree.train(trainset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluating the tree\n",
    "Training a ClassifierTree like this is a good start, but to get the most out of your tree the indidual nodes will need tweaking. To inspect the trees' performance call evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  Node | Depth | Parents              |  Classes |  Test size |   Test acc | \n",
      "|-------+-------+----------------------+----------+------------+------------|\n",
      "|     1 |     1 | .                    |       20 |       1200 |      1.92% | \n",
      "|     2 |     1 | FOOT                 |       13 |        151 |     11.92% | \n",
      "|     3 |     1 | PELVIS               |       13 |         60 |     100.0% | \n",
      "|     4 |     1 | SKULL                |        2 |          3 |     100.0% | \n",
      "|     5 |     1 | SHOULDER             |       17 |        102 |       0.0% | \n",
      "|     6 |     1 | TSPINE               |        3 |          9 |       0.0% | \n",
      "|     7 |     1 | CSPINE               |        1 |         23 |     100.0% | \n",
      "|     8 |     1 | CLAVICLE             |        5 |          1 |       0.0% | \n",
      "|     9 |     1 | SSPINE               |        1 |          0 |       N/A% | \n",
      "|    10 |     1 | ARM                  |        3 |          3 |       0.0% | \n",
      "|    11 |     1 | ANKLE                |        9 |         16 |       0.0% | \n",
      "|    12 |     1 | KNEE                 |       15 |        152 |     29.61% | \n",
      "|    13 |     1 | LSPINE               |        5 |         36 |       0.0% | \n",
      "|    14 |     1 | LEG                  |        3 |          2 |       0.0% | \n",
      "|    15 |     1 | ABDOMEN              |        3 |          7 |       0.0% | \n",
      "|    16 |     1 | ELBOW                |       14 |         92 |       0.0% | \n",
      "|    17 |     1 | HAND                 |       17 |         43 |       0.0% | \n",
      "|    18 |     1 | HIP                  |       10 |         63 |      1.59% | \n",
      "|    19 |     1 | VERTEBRAL COLUMN     |        8 |         55 |     41.82% | \n",
      "|    20 |     1 | EXTREMITY            |       20 |         85 |      3.53% | \n",
      "|    21 |     1 | CHEST                |       14 |        297 |      2.02% | \n"
     ]
    }
   ],
   "source": [
    "tree.evaluate(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Tweaking individual nodes in the tree\n",
    "From the evaluation we can see that node 2 appears to not be performing very well. To train this individual node, we first need to find it's path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gemicai.Classifier.Classifier'>\n",
      "['Voet links', 'Enkel links', 'Voet rechts', 'Voet links kind', 'Calcaneus rechts', 'Voet beiderzijds', 'Voet rechts kind', 'Enkel rechts', 'Teen rechts', 'Teen links', 'Calcaneus links', 'Enkel beiderzijds', 'Teen links kind']\n"
     ]
    }
   ],
   "source": [
    "parent = 'FOOT'\n",
    "\n",
    "# By default the filename of the node is <node.label>.gemnode\n",
    "node_path = '/mnt/SharedStor/trees/dx_tree/'+parent+'/StudyDescription.gemnode'\n",
    "\n",
    "node = gem.ClassifierNode.from_file(node_path)\n",
    "\n",
    "# Select neural network from the node\n",
    "net = node.classifier\n",
    "print(type(net))\n",
    "\n",
    "print(net.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, net is an instance of Gemicai.Classifier, we already know how to train a Classifier! For more information about Gemicai.Classifier see tutorial 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class (StudyDescription)   |   Frequency |\n",
      "|----------------------------+-------------|\n",
      "| Voet links                 |         164 |\n",
      "| Enkel links                |          98 |\n",
      "| Voet rechts                |         176 |\n",
      "| Voet links kind            |           6 |\n",
      "| Calcaneus rechts           |          14 |\n",
      "| Voet beiderzijds           |          95 |\n",
      "| Voet rechts kind           |           2 |\n",
      "| Enkel rechts               |         121 |\n",
      "| Teen rechts                |           9 |\n",
      "| Teen links                 |           7 |\n",
      "| Calcaneus links            |          13 |\n",
      "| Enkel beiderzijds          |          13 |\n",
      "| Teen links kind            |           2 |\n",
      "\n",
      "Total number of training images: 720 \n",
      "Total number of classes: 13\n",
      "\n",
      "| Class (StudyDescription)   |   Frequency |\n",
      "|----------------------------+-------------|\n",
      "| Voet rechts                |          35 |\n",
      "| Voet links                 |          45 |\n",
      "| Enkel links                |          18 |\n",
      "| Calcaneus links            |           3 |\n",
      "| Enkel rechts               |          23 |\n",
      "| Voet beiderzijds           |          16 |\n",
      "| Calcaneus rechts           |           6 |\n",
      "| Enkel beiderzijds          |           5 |\n",
      "\n",
      "Total number of training images: 151 \n",
      "Total number of classes: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "constraints = {\n",
    "    'BodyPartExamined': parent\n",
    "}\n",
    "\n",
    "trainsubset = trainset.subset(constraints)[1]\n",
    "testsubset = testset.subset(constraints)[1]\n",
    "\n",
    "\n",
    "trainsubset.summarize('StudyDescription')\n",
    "testsubset.summarize('StudyDescription')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch | Avg. loss | Train Acc. | Test Acc.  | Elapsed  |   ETA    |\n",
      "|-------+-----------+------------+------------+----------+----------|\n",
      "|     1 | 0.3117709 | 19.6%      | 23.33%     | 00:00:07 | 02:11:46 |\n",
      "|     2 | 0.3124463 | 19.6%      | 23.33%     | 00:00:15 | 02:15:00 |\n",
      "|     3 | 0.3124463 | 19.6%      | 23.33%     | 00:00:15 | 02:14:59 |\n",
      "|     4 | 0.3124463 | 19.6%      | 23.33%     | 00:00:14 | 02:14:58 |\n",
      "|     5 | 0.3124463 | 19.6%      | 23.33%     | 00:00:14 | 02:14:58 |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-8f27e5cf7d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainsubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestsubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/utilities/gemicai/Classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, batch_size, epochs, num_workers, pin_memory, verbosity, test_dataset, output_policy)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;31m# Evaluating models increases epoch time significantly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbosity\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/utilities/gemicai/Classifier.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, batch_size, num_workers, pin_memory, verbosity, output_policy)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mclass_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/utilities/gemicai/data_iterators.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/utilities/gemicai/data_iterators.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;31m# get next dicomo class from the stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0mdicomo_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicomo_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgemicai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDicomObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                     raise TypeError(\"pickled dataset should contain gemicai.data_iterators.DicomObject but it contains \"\n",
      "\u001b[0;32m~/utilities/gemicai/data_iterators.py\u001b[0m in \u001b[0;36m_stream_pickled_dicomos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ab+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mgem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munzip_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mgem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/utilities/gemicai/io/pickle.py\u001b[0m in \u001b[0;36munzip_to_file\u001b[0;34m(file, zip_path)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} should contain object of type {}, instead got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train(trainsubset, test_dataset=testsubset, epochs=25, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| <class 'list'> | <class 'list'> | <class 'list'> |\n",
      "| Class            |   Total |   Correct | Acc   |\n",
      "|------------------+---------+-----------+-------|\n",
      "| ELBOW            |      92 |         0 | 0.0%  |\n",
      "| VERTEBRAL COLUMN |      55 |         0 | 0.0%  |\n",
      "| CHEST            |     297 |         0 | 0.0%  |\n",
      "| PELVIS           |      60 |         0 | 0.0%  |\n",
      "| SHOULDER         |     102 |         0 | 0.0%  |\n",
      "| KNEE             |     152 |         0 | 0.0%  |\n",
      "| HIP              |      63 |         0 | 0.0%  |\n",
      "| FOOT             |     151 |         0 | 0.0%  |\n",
      "| EXTREMITY        |      85 |        56 | 65.9% |\n",
      "| LSPINE           |      36 |         0 | 0.0%  |\n",
      "| ABDOMEN          |       7 |         0 | 0.0%  |\n",
      "| HAND             |      43 |         0 | 0.0%  |\n",
      "| CSPINE           |      23 |         1 | 4.3%  |\n",
      "| ANKLE            |      16 |         0 | 0.0%  |\n",
      "| CLAVICLE         |       1 |         0 | 0.0%  |\n",
      "| LEG              |       2 |         0 | 0.0%  |\n",
      "| SKULL            |       3 |         0 | 0.0%  |\n",
      "| ARM              |       3 |         0 | 0.0%  |\n",
      "| TSPINE           |       9 |         1 | 11.1% |\n",
      "| SSPINE           |       0 |         0 | -     | \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.83, 1200, 58)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(testsubset, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.save()\n",
    "tree.evaluate(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can assign a whole new classifier to the node. First train the new and improved Classifier, then assign it to the node's classifier, then save the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "\n",
    "newnet = gem.Classifier(resnet18, trainsubset.classes('StudyDescription'), enable_cuda=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch | Avg. loss | Train Acc. | Test Acc.  | Elapsed  |   ETA    |\n",
      "|-------+-----------+------------+------------+----------+----------|\n",
      "|     1 | 0.2675403 | 63.47%     | 67.55%     | 00:00:09 | 03:36:34 |\n",
      "|     2 | 0.0992208 | 81.67%     | 82.78%     | 00:00:18 | 03:40:59 |\n",
      "|     3 | 0.0530914 | 80.83%     | 82.78%     | 00:00:17 | 03:40:34 |\n",
      "|     4 | 0.0440298 | 78.75%     | 78.81%     | 00:00:17 | 03:40:40 |\n",
      "|     5 | 0.0520361 | 83.33%     | 85.43%     | 00:00:17 | 03:40:35 |\n",
      "|     6 | 0.0373383 | 86.39%     | 87.42%     | 00:00:17 | 03:40:38 |\n",
      "|     7 | 0.0351050 | 83.89%     | 86.09%     | 00:00:17 | 03:40:34 |\n",
      "|     8 | 0.0240775 | 82.36%     | 80.79%     | 00:00:17 | 03:40:35 |\n",
      "|     9 | 0.0244584 | 83.89%     | 80.79%     | 00:00:17 | 03:40:31 |\n",
      "|    10 | 0.0201383 | 76.94%     | 74.17%     | 00:00:17 | 03:40:37 |\n",
      "|    11 | 0.0257878 | 81.94%     | 82.12%     | 00:00:17 | 03:40:36 |\n",
      "|    12 | 0.0247606 | 81.53%     | 82.78%     | 00:00:17 | 03:40:34 |\n",
      "|    13 | 0.0297228 | 84.44%     | 85.43%     | 00:00:17 | 03:40:35 |\n",
      "|    14 | 0.0198232 | 84.72%     | 86.75%     | 00:00:17 | 03:40:36 |\n",
      "|    15 | 0.0165070 | 86.25%     | 85.43%     | 00:00:17 | 03:40:38 |\n",
      "|    16 | 0.0142836 | 85.83%     | 82.12%     | 00:00:17 | 03:40:33 |\n",
      "|    17 | 0.0130183 | 80.28%     | 78.15%     | 00:00:17 | 03:40:33 |\n",
      "|    18 | 0.0214196 | 94.17%     | 92.05%     | 00:00:17 | 03:40:35 |\n",
      "|    19 | 0.0138551 | 87.08%     | 84.77%     | 00:00:17 | 03:40:36 |\n",
      "|    20 | 0.0122548 | 83.19%     | 80.79%     | 00:00:17 | 03:40:35 |\n",
      "|    21 | 0.0107900 | 87.92%     | 85.43%     | 00:00:17 | 03:40:34 |\n",
      "|    22 | 0.0107373 | 80.28%     | 80.79%     | 00:00:17 | 03:40:35 |\n",
      "|    23 | 0.0141244 | 89.72%     | 92.05%     | 00:00:17 | 03:40:36 |\n",
      "|    24 | 0.0152829 | 76.67%     | 76.82%     | 00:00:17 | 03:40:36 |\n",
      "|    25 | 0.0070376 | 89.44%     | 89.4%      | 00:00:17 | 03:40:35 |\n",
      "|    26 | 0.0124144 | 92.64%     | 91.39%     | 00:00:17 | 03:40:36 |\n",
      "|    27 | 0.0127167 | 91.25%     | 93.38%     | 00:00:17 | 03:40:35 |\n",
      "|    28 | 0.0027454 | 93.47%     | 94.04%     | 00:00:17 | 03:40:35 |\n",
      "|    29 | 0.0012205 | 97.22%     | 98.01%     | 00:00:17 | 03:40:35 |\n",
      "|    30 | 0.0019410 | 94.72%     | 94.7%      | 00:00:17 | 03:40:35 |\n",
      "Training finished, total time elapsed: 0:00:08.813232\n",
      "| <class 'list'> | <class 'list'> | <class 'list'> |\n",
      "| Class             |   Total |   Correct | Acc    |\n",
      "|-------------------+---------+-----------+--------|\n",
      "| Voet links        |      45 |        37 | 82.2%  |\n",
      "| Enkel links       |      18 |        18 | 100.0% |\n",
      "| Voet rechts       |      35 |        35 | 100.0% |\n",
      "| Voet links kind   |       0 |         0 | -      |\n",
      "| Calcaneus rechts  |       6 |         6 | 100.0% |\n",
      "| Voet beiderzijds  |      16 |        16 | 100.0% |\n",
      "| Voet rechts kind  |       0 |         0 | -      |\n",
      "| Enkel rechts      |      23 |        23 | 100.0% |\n",
      "| Teen rechts       |       0 |         0 | -      |\n",
      "| Teen links        |       0 |         0 | -      |\n",
      "| Calcaneus links   |       3 |         3 | 100.0% |\n",
      "| Enkel beiderzijds |       5 |         5 | 100.0% |\n",
      "| Teen links kind   |       0 |         0 | -      | \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94.7, 151, 143)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "newnet.train(trainsubset, test_dataset=testsubset, epochs=30, verbosity=2)\n",
    "\n",
    "newnet.evaluate(testsubset, verbosity=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are satisfied the with networks performance, we can write it back to the node and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/SharedStor/trees/dx_tree/FOOT/StudyDescription.gemnode\n"
     ]
    }
   ],
   "source": [
    "print(node.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node.classifier = newnet\n",
    "\n",
    "node.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when, evaluating the tree again, we can see that the accuracy of node 2 improved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  Node | Depth | Parents              |  Classes |  Test size |   Test acc | \n",
      "|-------+-------+----------------------+----------+------------+------------|\n",
      "|     1 |     1 | .                    |       20 |       1200 |     99.92% | \n",
      "|     2 |     1 | FOOT                 |       13 |        151 |     11.92% | \n",
      "|     3 |     1 | PELVIS               |       13 |         60 |     100.0% | \n",
      "|     4 |     1 | SKULL                |        2 |          3 |     100.0% | \n",
      "|     5 |     1 | SHOULDER             |       17 |        102 |       0.0% | \n",
      "|     6 |     1 | TSPINE               |        3 |          9 |       0.0% | \n",
      "|     7 |     1 | CSPINE               |        1 |         23 |     100.0% | \n",
      "|     8 |     1 | CLAVICLE             |        5 |          1 |       0.0% | \n",
      "|     9 |     1 | SSPINE               |        1 |          0 |       N/A% | \n",
      "|    10 |     1 | ARM                  |        3 |          3 |       0.0% | \n",
      "|    11 |     1 | ANKLE                |        9 |         16 |       0.0% | \n",
      "|    12 |     1 | KNEE                 |       15 |        152 |      2.63% | \n",
      "|    13 |     1 | LSPINE               |        5 |         36 |       0.0% | \n",
      "|    14 |     1 | LEG                  |        3 |          2 |       0.0% | \n",
      "|    15 |     1 | ABDOMEN              |        3 |          7 |       0.0% | \n",
      "|    16 |     1 | ELBOW                |       14 |         92 |       0.0% | \n",
      "|    17 |     1 | HAND                 |       17 |         43 |       0.0% | \n",
      "|    18 |     1 | HIP                  |       10 |         63 |      1.59% | \n",
      "|    19 |     1 | VERTEBRAL COLUMN     |        8 |         55 |      40.0% | \n",
      "|    20 |     1 | EXTREMITY            |       20 |         85 |      3.53% | \n",
      "|    21 |     1 | CHEST                |       14 |        297 |      2.69% | \n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree.evaluate(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_doubles(a, b):\n",
    "    total, doubles = 0, 0\n",
    "    for data in a:\n",
    "        for d in b:\n",
    "            if (data[0].numpy() == d[0].numpy()).all():\n",
    "                doubles += 1\n",
    "                break\n",
    "        total += 1\n",
    "    print('Total: {}  Doubles: {}'.format(total, doubles))\n",
    "    \n",
    "    \n",
    "count_doubles(trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_doubles(testset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
