{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemicai tutorial 3: Gemicai Dataset\n",
    "This tutorial is about everything concerning Gemicai datasets, or gemsets for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemicai as gem\n",
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green\"> @Mateusz theres some simple functionality I think the gemsets should have in the beta release, could you implement this? </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Initialize gemset\n",
    "Some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Extension   |   Files | Size    |\n",
      "|-------------+---------+---------|\n",
      "| .dcm.gz     |    1061 | 5.75 GB | \n",
      "\n",
      "| Extension   |   Files | Size    |\n",
      "|-------------+---------+---------|\n",
      "| .gemset     |      11 | 31.6 MB | \n",
      "\n",
      "| Class (SeriesDescription)          |   Frequency |\n",
      "|------------------------------------+-------------|\n",
      "| R MLO                              |         227 |\n",
      "| R CC                               |         235 |\n",
      "| L CC                               |         219 |\n",
      "| None                               |          57 |\n",
      "| L LM                               |          12 |\n",
      "| L MLO                              |         218 |\n",
      "| L XCCL                             |          16 |\n",
      "| L SPECIMEN                         |          12 |\n",
      "| Mammografie SVOB beiderzijds       |           4 |\n",
      "| R SPECIMEN                         |          12 |\n",
      "| Mammopunctie stereotactisch rechts |           4 |\n",
      "| R LM                               |          11 |\n",
      "| R XCCL                             |          18 |\n",
      "| Mammopunctie stereotactisch links  |          10 |\n",
      "| R CCID                             |           2 |\n",
      "| L CCID                             |           2 |\n",
      "| Mammografie mammapoli beiderzijds  |           1 |\n",
      "| L MLOID                            |           1 |\n",
      "\n",
      "Total number of training images: 1061 \n",
      "Total number of classes: 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dicom_data = '/mnt/SharedStor/tutorials/Mammography/'\n",
    "\n",
    "# Let's find out how many dicom images we have.\n",
    "gem.utils.dir_info(dicom_data)\n",
    "\n",
    "gemset_destination = '/mnt/SharedStor/tutorials/tutorial3'\n",
    "\n",
    "# Specify the relevant Dicom attributes you want to use.\n",
    "dicom_attributes = ['Modality', 'BodyPartExamined', 'StudyDescription', 'SeriesDescription']\n",
    "\n",
    "\n",
    "# gem.dicom_to_gemset(data_origin=dicom_data, data_destination=gemset_destination, relevant_labels=dicom_attributes, \n",
    "#                     objects_per_file=100, test_split=0.2, verbosity=1)\n",
    "\n",
    "gem.utils.dir_info(gemset_destination)\n",
    "\n",
    "gemset = gem.DicomoDataset.get_dicomo_dataset(gemset_destination, labels=dicom_attributes)\n",
    "\n",
    "gemset.summarize('SeriesDescription')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tweaking gemset\n",
    "To get the most out of your neural network, data selection is very important. Some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class (SeriesDescription)   |   Frequency |\n",
      "|-----------------------------+-------------|\n",
      "| R MLO                       |         227 |\n",
      "| R CC                        |         235 |\n",
      "| L CC                        |         219 |\n",
      "| L LM                        |          12 |\n",
      "| L MLO                       |         218 |\n",
      "| L XCCL                      |          16 |\n",
      "| L SPECIMEN                  |          12 |\n",
      "| R SPECIMEN                  |          12 |\n",
      "| R LM                        |          11 |\n",
      "| R XCCL                      |          18 |\n",
      "\n",
      "Total number of training images: 980 \n",
      "Total number of classes: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# These are all orientations we are interested in classifing.\n",
    "orientations = ['L MLO', 'R MLO', 'L CC', 'R CC', 'L LM', 'R LM', 'L XCCL', 'R XCCL', 'L SPECIMEN', 'R SPECIMEN']\n",
    "\n",
    "constraints = {\n",
    "    'Modality': 'MG',\n",
    "    'SeriesDescription': orientations,\n",
    "}\n",
    "\n",
    "subset = gemset.subset(constraints)\n",
    "\n",
    "subset.summarize('SeriesDescription')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GemicaiDataset.save()\n",
    "<p style=\"color:green\"> .subset right now doesnt make a new gemset, it just applies constraints on an existing gemset, this needs to be explained. Also, if the subset is small compared the original gemset, its performance will be significantly worse. Therefore we sometimes might want to create a subset from a gemset and store it else where. GemicaiDataset should have a function self.save(dir) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe(self, dir):\n",
    "    #TODO: implement function\n",
    "    pass\n",
    "\n",
    "subset.save('example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GemicaiDataset.erase()\n",
    "<p style=\"color:green\"> We might also want to delete obsolete gemsets </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase(self):\n",
    "    #TODO: implement function\n",
    "    pass\n",
    "\n",
    "gemset.erase()\n",
    "gemset = subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GemicaiDataset.split()\n",
    "<p style=\"color:green\"> We almost always need to split the dataset in to a train- and test-dataset, why not make a function for this. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(self, ratio, sets=['train', 'test'], self_erase_afterwards=False):\n",
    "    if isinstance(ratio, int):\n",
    "        ratio = [1 - ratio, ratio]\n",
    "    \n",
    "    assert len(ratio) == len(sets), 'Specify a ratio for every set you want to create'\n",
    "    assert sum(ratio) == 1, 'The sum of all ratios should be 1'\n",
    "    \n",
    "    for i, s in enumerate(sets):\n",
    "        subset = None\n",
    "        # TODO: create random subset\n",
    "        subset.save(os.path.join(self.base_path, s))\n",
    "    \n",
    "    if self_erase_afterwards:\n",
    "        self.erase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This splits the gemset into a training set with 80% of the original gemsets' size,  and a test set with 20% of the original gemsets' size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemset.split(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green\"> This creates a test-, validation- and test-set. This is a quite standard thing people in machine learning want to do </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemset.split(ratio=[0.7, 0.15, 0.15], sets=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GemicaiDataset.__getitem__()\n",
    "<p style=\"color:green\"> When passing a gemset with more than 1 label to a classifier, it crashes (I put in the exception handling but otherwise it still crashes). I figured that it might be nice to use __getitem__ to fix this, what do you think? </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __getitem__(self, arg):\n",
    "    if isistance(arg, int):\n",
    "        arg = self.labels[arg]\n",
    "    if arg not in self.labels:\n",
    "        raise ValueError('Specified argument not in gemset labels. Valid labels are: {}'.format(self.labels))\n",
    "    return type(self)(path=self.path, labels=[arg], transform=self.transform, constraints=self.constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specify what label should be classified. This dataset containts the labels ['Modality', 'BodyPartExamined', 'StudyDescription', 'SeriesDescription']. E.g. tryagain dataset['Modality'] or dataset[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-01c21a505be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgemset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SeriesDescription'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgemset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/utilities/gemicai/Classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, batch_size, epochs, num_workers, pin_memory, verbosity, test_dataset, output_policy)\u001b[0m\n\u001b[1;32m     54\u001b[0m     def train(self, dataset, batch_size=4, epochs=20, num_workers=0, pin_memory=False,\n\u001b[1;32m     55\u001b[0m               verbosity=0, test_dataset=None, output_policy=policy.ToConsole()):\n\u001b[0;32m---> 56\u001b[0;31m         Classifier.validate_dataset_parameters(dataset, batch_size, epochs, num_workers, pin_memory,\n\u001b[0m\u001b[1;32m     57\u001b[0m                                                test_dataset, verbosity, output_policy)\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/utilities/gemicai/Classifier.py\u001b[0m in \u001b[0;36mvalidate_dataset_parameters\u001b[0;34m(dataset, batch_size, epochs, num_workers, pin_memory, test_dataset, verbosity, output_policy)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             raise ValueError('Specify what label should be classified. This dataset containts the labels {}. E.g. try'\n\u001b[0m\u001b[1;32m    230\u001b[0m                              'again dataset[\\'{}\\'] or dataset[0]'.format(dataset.labels, dataset.labels[0]))\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Specify what label should be classified. This dataset containts the labels ['Modality', 'BodyPartExamined', 'StudyDescription', 'SeriesDescription']. E.g. tryagain dataset['Modality'] or dataset[0]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize classifier\n",
    "net = gem.Classifier(models.resnet18(pretrained=True), gemset.classes('SeriesDescription'), enable_cuda=True)\n",
    "\n",
    "net.train(gemset, epochs=5, verbosity=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cc787a744abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If implemented correctly this should work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgemset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SeriesDescription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This does the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgemset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gemicai/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# If implemented correctly this should work\n",
    "net.train(gemset['SeriesDescription'], epochs=5, verbosity=1)\n",
    "\n",
    "# This does the same\n",
    "net.train(gemset[3], epochs=5, verbosity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct dataset\n",
    "<p style=\"color:green\"> Rn this function is in gemicai/data_inpection.py and does nothing yet. Can you implement this and make it as user friendly as possible? I presume mostly radiologist will be using this function </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem.correct_dataset(net, gemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
